{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK \n",
    "Здесь собраны примеры работы с основными функциями NLTK.<br>\n",
    "Мы узнаем следующее:<br>\n",
    "* Сегментация слов - разделите текст на предложения и слова.\n",
    "* Пометка части речи\n",
    "* Машинное обучение и наивный байесовский классификатор\n",
    "* Как использовать Scikit Learn (sklearn) и NLTK вместе\n",
    "* Обучите классификатор с набором данных\n",
    "* Используйте Twitter для анализа настроений в реальном времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text = \"\"\"\n",
    "Я ПИШУ ДЛЯ ЛЮДЕЙ, ПЛОХО ЗНАЮЩИХ РОССИЙСКУЮ ИСТОРИЮ И ЖЕЛАЮЩИХ В НЕЙ РАЗОБРАТЬСЯ. Я и сам такой же. Всю жизнь я \n",
    "интересовался историей, получил историческое образование, написал несколько десятков исторических романов и \n",
    "тем не менее однажды осознал, что мои знания состоят из отдельных фрагментов, плохо складывающихся в общую картину. \n",
    "У меня не было ясного представления о том, как и почему Россия получилась именно такой. И я понял: чтобы ответить \n",
    "на столь краткий вопрос, \n",
    "придется сначала прочитать десятки тысяч страниц, а потом несколько тысяч страниц написать.\n",
    "Я НЕ ВЫСТРАИВАЮ НИКАКОЙ КОНЦЕПЦИИ. У меня ее нет. Всякий историк, создающий собственную теорию, не может совладать \n",
    "с искушением выпятить удобные для себя факты и замолчать либо подвергнуть сомнению всё, что в его логику не \n",
    "вписывается. У меня такого соблазна не было.\n",
    "Кроме того, я решительный противник идеологизированной истории. И самовосхвалительная, и самоуничижительная линии, \n",
    "обильно представленные в трудах отечественных историков, мне одинаково неинтересны. Я хочу узнать (или вычислить), \n",
    "как было на самом деле. У меня нет заранее сложившегося мнения. Есть вопросы и есть желание найти на них ответы.\n",
    "ЭТО ИСТОРИЯ НЕ СТРАНЫ, А ИМЕННО ГОСУДАРСТВА, то есть политическая история: государственного строительства, \n",
    "механизмов управления, взаимоотношения народа и власти, общественной эволюции. Культуры, религии, экономики я \n",
    "касаюсь лишь в той мере, в какой они связаны с политикой.\n",
    "Россия – это прежде всего государство. Оно не тождественно стране, а в отдельные моменты истории бывало ей даже \n",
    "враждебно, но именно состояние государства неизменно определяло вектор эволюции (или деградации) всех сфер \n",
    "российской жизни. Государство – причина и российских бед, и российских побед.\n",
    "Попытка понять, что в нашем тысячелетнем государстве так и что не так (и почему) – вот для чего в конечном итоге \n",
    "затеяна эта работа.\n",
    "Предисловие ко второму тому\n",
    "Том «Часть Азии» описывает тот период отечественной истории, когда Руси, можно сказать, не было. Жили люди, \n",
    "говорившие по-русски, соблюдались русские обычаи, сохранялась русская вера, но страны не существовало – и долго \n",
    "не существовало, два с лишним века, с 1238 года до середины пятнадцатого столетия.\n",
    "По поводу точной даты окончания монгольского владычества есть разные точки зрения. Чаще всего называют 1480 год, \n",
    "когда была официально провозглашена независимость Москвы от ханов, но я согласен с теми историками, кто относит \n",
    "конец этой эпохи к несколько более раннему времени. Поэтому я закончу повествование годом смерти Василия \n",
    "Темного – государя, к концу правления которого Русь избавилась от ордынского засилия фактически. С восхождением на \n",
    "престол Ивана III начинается новый исторический этап, которому правильнее будет посвятить отдельный том.\n",
    "Хронологические рамки второго тома «Истории Российского государства» охватывают события от 1223 года (первое \n",
    "столкновение русских с монголами) до 1462 года (смерть последнего великого князя, получившего ярлык в Орде).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Я ПИШУ ДЛЯ ЛЮДЕЙ, ПЛОХО ЗНАЮЩИХ РОССИЙСКУЮ ИСТОРИЮ И ЖЕЛАЮЩИХ В НЕЙ РАЗОБРАТЬСЯ.\n",
      "------------------------------\n",
      "Я и сам такой же.\n",
      "------------------------------\n",
      "Всю жизнь я \n",
      "интересовался историей, получил историческое образование, написал несколько десятков исторических романов и \n",
      "тем не менее однажды осознал, что мои знания состоят из отдельных фрагментов, плохо складывающихся в общую картину.\n",
      "------------------------------\n",
      "У меня не было ясного представления о том, как и почему Россия получилась именно такой.\n",
      "------------------------------\n",
      "И я понял: чтобы ответить \n",
      "на столь краткий вопрос, \n",
      "придется сначала прочитать десятки тысяч страниц, а потом несколько тысяч страниц написать.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# токены - предложения\n",
    "sentences = sent_tokenize(source_text)\n",
    "for k in range(5):\n",
    "    print(sentences[k])\n",
    "    print('-'*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я\n",
      "ПИШУ\n",
      "ДЛЯ\n",
      "ЛЮДЕЙ\n",
      ",\n"
     ]
    }
   ],
   "source": [
    "# токены - слова\n",
    "words = word_tokenize(source_text)\n",
    "for k in range(5):\n",
    "    print(words[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['а', 'без', 'более', 'больше', 'будет', 'будто', 'бы', 'был', 'была', 'были', 'было', 'быть', 'в', 'вам', 'вас', 'вдруг', 'ведь', 'во', 'вот', 'впрочем', 'все', 'всегда', 'всего', 'всех', 'всю', 'вы', 'где', 'да', 'даже', 'два', 'для', 'до', 'другой', 'его', 'ее', 'ей', 'ему', 'если', 'есть', 'еще', 'ж', 'же', 'за', 'зачем', 'здесь', 'и', 'из', 'или', 'им', 'иногда', 'их', 'к', 'как', 'какая', 'какой', 'когда', 'конечно', 'кто', 'куда', 'ли', 'лучше', 'между', 'меня', 'мне', 'много', 'может', 'можно', 'мой', 'моя', 'мы', 'на', 'над', 'надо', 'наконец', 'нас', 'не', 'него', 'нее', 'ней', 'нельзя', 'нет', 'ни', 'нибудь', 'никогда', 'ним', 'них', 'ничего', 'но', 'ну', 'о', 'об', 'один', 'он', 'она', 'они', 'опять', 'от', 'перед', 'по', 'под', 'после', 'потом', 'потому', 'почти', 'при', 'про', 'раз', 'разве', 'с', 'сам', 'свою', 'себе', 'себя', 'сейчас', 'со', 'совсем', 'так', 'такой', 'там', 'тебя', 'тем', 'теперь', 'то', 'тогда', 'того', 'тоже', 'только', 'том', 'тот', 'три', 'тут', 'ты', 'у', 'уж', 'уже', 'хорошо', 'хоть', 'чего', 'чем', 'через', 'что', 'чтоб', 'чтобы', 'чуть', 'эти', 'этого', 'этой', 'этом', 'этот', 'эту', 'я']\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "# Получаем стандартный список стоп слов\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = sorted(set(stopwords.words('russian')))\n",
    "print(stop_words)     \n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "получила\n",
      "историческое\n",
      "образованием\n",
      "написали\n",
      "несколько\n",
      "десятков\n",
      "исторических\n",
      "романов\n"
     ]
    }
   ],
   "source": [
    "# Концепция стемминга для русского языка в стандартной библиотеке PorterStemmer не работает\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "example_words = ['получила', 'историческое', 'образованием', 'написали', 'несколько', 'десятков', 'исторических', 'романов']\n",
    "for w in example_words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "получила -> получ\n",
      "историческое -> историческ\n",
      "образованием -> образован\n",
      "написали -> написа\n",
      "несколько -> нескольк\n",
      "десятков -> десятк\n",
      "исторических -> историческ\n",
      "романов -> роман\n"
     ]
    }
   ],
   "source": [
    "# Концепция стемминга для русского языка в стандартной библиотеке SnowballStemmer работает\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snow_stemmer = SnowballStemmer(language='russian')\n",
    "for word in example_words:\n",
    "    print(word+' -> '+snow_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "получила -> получ\n",
      "историческое -> историческ\n",
      "образованием -> образован\n",
      "написали -> написа\n",
      "несколько -> нескольк\n",
      "десятков -> десятк\n",
      "исторических -> историческ\n",
      "романов -> роман\n"
     ]
    }
   ],
   "source": [
    "# Второй способ сделать тоже самое\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "snow_stemmer = RussianStemmer()\n",
    "for word in example_words:\n",
    "    print(word+' -> '+snow_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
