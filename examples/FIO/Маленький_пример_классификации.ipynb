{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14650\n"
     ]
    }
   ],
   "source": [
    "name_file_6 = '/home/al/PycharmProjects/NLP-russian-language/datasets/datasets_with_name_peaple/male_surnames_rus.txt'\n",
    "k = 0 \n",
    "fameli = []\n",
    "with open(name_file_6) as is_file:\n",
    "    for line in is_file:\n",
    "        if k!=0:\n",
    "            fameli.append(line.strip().lower())\n",
    "        k = 1\n",
    "print(len(set(fameli)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14650\n"
     ]
    }
   ],
   "source": [
    "def get_array_obj(fameli):\n",
    "    array_ish = []\n",
    "    for ww in fameli:\n",
    "       array_ish.append(list(ww))\n",
    "    print(len(array_ish))\n",
    "    return array_ish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fameli_ish = get_array_obj(fameli)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['абаимов абаи баим аимо имов', 'абакишин абак баки акиш киши ишин', 'абакулин абак баку акул кули улин', 'абакулов абак баку акул куло улов', 'абакумкин абак баку акум кумк умки мкин', 'абакумов абак баку акум кумо умов', 'абакушин абак баку акуш куши ушин', 'абакшин абак бакш акши кшин', 'абалакин абал бала алак лаки акин', 'абалаков абал бала алак лако аков']\n"
     ]
    }
   ],
   "source": [
    "alfa = ['а','б','в','г','д','е','ё','и','й','ж','з','к','л','м','н','о',\n",
    "              'п','р','с','т','у','ч','ш','щ','ц','ф','х','ь','ъ','э','ю','я', ' ']\n",
    "k = 0\n",
    "sentenses = []\n",
    "for dd in array_ish:\n",
    "    servis_list =[]\n",
    "    word = ''.join(dd)\n",
    "    servis_list.append(word)\n",
    "    ngg = list(ngrams(dd, 4))\n",
    "    for nn in ngg:\n",
    "        word = ''.join(nn)\n",
    "        servis_list.append(word)\n",
    "    sentenses.append(' '.join(servis_list))\n",
    "    #sentenses.append([' '.join(servis_list),'фамилия'])\n",
    "    k +=1\n",
    "    if k == 10: break\n",
    "print(sentenses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "columns = ['sent', 'class']\n",
    "X_train_counts = vectorizer.fit_transform(sentenses)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = vectorizer2.fit_transform(sentenses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['абаи баим', 'абаимов абаи', 'абак баки', 'абак баку', 'абак бакш', 'абакишин абак', 'абакулин абак', 'абакулов абак', 'абакумкин абак', 'абакумов абак', 'абакушин абак', 'абакшин абак', 'абал бала', 'абалакин абал', 'абалаков абал', 'аимо имов', 'акиш киши', 'акул кули', 'акул куло', 'акум кумк', 'акум кумо', 'акуш куши', 'акши кшин', 'алак лаки', 'алак лако', 'баим аимо', 'баки акиш', 'баку акул', 'баку акум', 'баку акуш', 'бакш акши', 'бала алак', 'киши ишин', 'кули улин', 'куло улов', 'кумк умки', 'кумо умов', 'куши ушин', 'лаки акин', 'лако аков', 'умки мкин']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
